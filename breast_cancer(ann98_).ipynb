{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDNzHja3vIPv4M2QR+qKw9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-jobs/Calypso/blob/main/breast_cancer(ann98_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXVBw0MJPHbR"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Hyperparameters\n",
        "lambda_values = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
        "epochs = 150\n",
        "initial_learning_rate = 0.01\n",
        "\n",
        "# Load and cache data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv('bcdataset.csv')\n",
        "    df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')\n",
        "    df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "    return df\n",
        "\n",
        "# Preprocess: Train / CV / Test split\n",
        "def preprocess_data(df):\n",
        "    X = df.drop(columns='diagnosis')\n",
        "    y = df['diagnosis']\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)\n",
        "    X_cv, X_test, y_cv, y_test = train_test_split(X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42)\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_cv_scaled = scaler.transform(X_cv)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    pca = PCA(n_components=0.95)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_cv_pca = pca.transform(X_cv_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    return X_train_pca, y_train_res, X_cv_pca, y_cv, X_test_pca, y_test, scaler, pca, X.columns.tolist()\n",
        "\n",
        "# Lambda tuning with early stopping\n",
        "def tune_lambda(X_train, y_train, X_cv, y_cv):\n",
        "    train_errors, cv_errors = [], []\n",
        "\n",
        "    for lam in lambda_values:\n",
        "        model = Sequential([\n",
        "            Input(shape=(X_train.shape[1],)),\n",
        "            Dense(100, activation='relu', kernel_regularizer=regularizers.l2(lam)),\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=initial_learning_rate),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        )\n",
        "\n",
        "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
        "\n",
        "        model.fit(X_train, y_train, validation_data=(X_cv, y_cv),\n",
        "                  epochs=epochs, batch_size=16, verbose=0, callbacks=[early_stop])\n",
        "\n",
        "        y_train_pred = tf.sigmoid(model.predict(X_train)).numpy().flatten()\n",
        "        y_cv_pred = tf.sigmoid(model.predict(X_cv)).numpy().flatten()\n",
        "\n",
        "        train_errors.append(1 - accuracy_score(y_train, y_train_pred > 0.5))\n",
        "        cv_errors.append(1 - accuracy_score(y_cv, y_cv_pred > 0.5))\n",
        "\n",
        "    return train_errors, cv_errors\n",
        "\n",
        "def plot_lambda_errors(train_errors, cv_errors):\n",
        "    log_lambdas = [np.log10(l) if l > 0 else -4 for l in lambda_values]\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(log_lambdas, train_errors, marker='o', label='Train Error')\n",
        "    plt.plot(log_lambdas, cv_errors, marker='o', label='CV Error')\n",
        "    plt.xlabel('log₁₀(λ)')\n",
        "    plt.ylabel('Fractional Error (1 - Accuracy)')\n",
        "    plt.title('Train vs CV Error vs λ')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    st.pyplot(plt)\n",
        "\n",
        "# Final training with best lambda\n",
        "def train_final_model(X_train, y_train, X_cv, y_cv, X_test, y_test, cv_errors):\n",
        "    best_idx = np.argmin(cv_errors)\n",
        "    best_lambda = lambda_values[best_idx]\n",
        "    st.markdown(f\"**✅ Best λ = {best_lambda} (CV Error = {cv_errors[best_idx]:.4f})**\")\n",
        "\n",
        "    X_final = np.vstack([X_train, X_cv])\n",
        "    y_final = np.concatenate([y_train, y_cv])\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(X_final.shape[1],)),\n",
        "        Dense(100, activation='relu', kernel_regularizer=regularizers.l2(best_lambda)),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=initial_learning_rate),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_final, y_final, epochs=epochs, batch_size=16, verbose=0)\n",
        "\n",
        "    # Evaluation\n",
        "    y_probs = tf.sigmoid(model.predict(X_test)).numpy().flatten()\n",
        "    y_preds = (y_probs > 0.5).astype(int)\n",
        "    auc = roc_auc_score(y_test, y_probs)\n",
        "    report = classification_report(y_test, y_preds, output_dict=True)\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
        "\n",
        "    st.markdown(f\"### 🎯 Final Test AUC: `{auc:.4f}`\")\n",
        "    st.subheader(\"📋 Classification Report\")\n",
        "    st.json({k: {m: round(v, 4) for m, v in v_dict.items()} if isinstance(v_dict, dict) else round(v_dict, 4)\n",
        "             for k, v_dict in report.items()})\n",
        "\n",
        "    st.subheader(\"📈 ROC Curve\")\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel(\"FPR\")\n",
        "    plt.ylabel(\"TPR\")\n",
        "    plt.title(\"ROC Curve - Final Model\")\n",
        "    plt.legend()\n",
        "    st.pyplot(plt)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"🤖 Breast Cancer Detection with ANN and Regularization\")\n",
        "\n",
        "df = load_data()\n",
        "X_train, y_train, X_cv, y_cv, X_test, y_test, scaler, pca, feature_names = preprocess_data(df)\n",
        "\n",
        "if st.checkbox(\"🔍 Perform Lambda Tuning & Select Best Model\"):\n",
        "    train_errors, cv_errors = tune_lambda(X_train, y_train, X_cv, y_cv)\n",
        "    plot_lambda_errors(train_errors, cv_errors)\n",
        "    final_model = train_final_model(X_train, y_train, X_cv, y_cv, X_test, y_test, cv_errors)\n",
        "else:\n",
        "    # Simple fallback model if tuning not chosen\n",
        "    model = Sequential([\n",
        "        Input(shape=(X_train.shape[1],)),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=initial_learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=16, verbose=0)\n",
        "    final_model = model\n",
        "\n",
        "# Manual Prediction\n",
        "st.subheader(\"🔍 Manual Input Prediction\")\n",
        "input_values = []\n",
        "cols = st.columns(3)\n",
        "for i, feature in enumerate(feature_names):\n",
        "    with cols[i % 3]:\n",
        "        val = st.number_input(feature, value=float(df[feature].mean()), format=\"%.4f\")\n",
        "        input_values.append(val)\n",
        "\n",
        "if st.button(\"Predict Diagnosis\"):\n",
        "    df_input = pd.DataFrame([input_values], columns=feature_names)\n",
        "    scaled = scaler.transform(df_input)\n",
        "    pca_transformed = pca.transform(scaled)\n",
        "    logit_pred = final_model.predict(pca_transformed)\n",
        "    prob = tf.sigmoid(logit_pred).numpy().flatten()[0]\n",
        "    label = \"Malignant\" if prob > 0.5 else \"Benign\"\n",
        "    st.success(f\"🎯 Prediction: {label} (Confidence: {prob:.4f})\")\n",
        "\n",
        "# Batch Prediction\n",
        "st.subheader(\"📁 Predict from CSV File\")\n",
        "file = st.file_uploader(\"Upload CSV with features\", type=[\"csv\"])\n",
        "if file:\n",
        "    try:\n",
        "        csv = pd.read_csv(file)\n",
        "        scaled = scaler.transform(csv)\n",
        "        pca_transformed = pca.transform(scaled)\n",
        "        logits = final_model.predict(pca_transformed)\n",
        "        probs = tf.sigmoid(logits).numpy().flatten()\n",
        "        csv[\"Diagnosis\"] = [\"Malignant\" if p > 0.5 else \"Benign\" for p in probs]\n",
        "        csv[\"Confidence\"] = [round(p, 4) for p in probs]\n",
        "        st.write(csv)\n",
        "    except Exception as e:\n",
        "        st.error(\"Error processing file. Check formatting.\")"
      ]
    }
  ]
}